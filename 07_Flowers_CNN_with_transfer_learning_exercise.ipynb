{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07 Flowers CNN with transfer learning exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnLY/wOSZSeUBgHG+n9TjI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelounb/tensorflow_udacity/blob/master/07_Flowers_CNN_with_transfer_learning_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pek6H3XmSsce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Imports for the CNN\n",
        "from keras.layers import Flatten \n",
        "from keras.layers.convolutional import Convolution2D \n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras import backend as K \n",
        "from random import randrange"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gocPcdkpTX4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uLJZHZoTgTd",
        "colab_type": "text"
      },
      "source": [
        "# Download the Flowers Dataset using TensorFlow Datasets\n",
        "In the cell below you will download the Flowers dataset using TensorFlow Datasets. If you look at the TensorFlow Datasets documentation you will see that the name of the Flowers dataset is tf_flowers. \n",
        "\n",
        "You can also see that this dataset is only split into a TRAINING set. You will therefore have to use tfds.splits to split this training set into to a training_set and a validation_set. Do a [70, 30] split such that 70 corresponds to the training_set and 30 to the validation_set. \n",
        "\n",
        "Then load the tf_flowers dataset using tfds.load. Make sure the tfds.load function uses the all the parameters you need, and also make sure it returns the dataset info, so we can retrieve information about the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdfKRxnGPIjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(training_set, validation_set), dataset_info = tfds.load(\n",
        "    'tf_flowers', \n",
        "    with_info=True, \n",
        "    as_supervised=True, \n",
        "    split=['train[:70%]', 'train[70%:]'],\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHXxe9tlP5j1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "423b5b8a-6eb0-419c-fcfb-023070dfc7ba"
      },
      "source": [
        "dataset_info"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='tf_flowers',\n",
              "    version=3.0.0,\n",
              "    description='A large set of images of flowers',\n",
              "    homepage='https://www.tensorflow.org/tutorials/load_data/images',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
              "    }),\n",
              "    total_num_examples=3670,\n",
              "    splits={\n",
              "        'train': 3670,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@ONLINE {tfflowers,\n",
              "    author = \"The TensorFlow Team\",\n",
              "    title = \"Flowers\",\n",
              "    month = \"jan\",\n",
              "    year = \"2019\",\n",
              "    url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asOWSxiJTVih",
        "colab_type": "text"
      },
      "source": [
        "# Print Information about the Flowers Dataset\n",
        "Now that you have downloaded the dataset, use the dataset info to print the number of classes in the dataset, and also write some code that counts how many images we have in the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_udfzfrTaC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "bafb4c1d-1823-43f4-85fd-3c4330c0c6f0"
      },
      "source": [
        "num_training_examples, num_validation_examples = 0,0\n",
        "\n",
        "for item in training_set:\n",
        "  num_training_examples +=1\n",
        "\n",
        "for item in validation_set:\n",
        "  num_validation_examples +=1\n",
        "\n",
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "print('Total Number of Classes: {}'.format(num_classes))\n",
        "print('Total Number of Training Images: {}'.format(num_training_examples))\n",
        "print('Total Number of Validation Images: {} \\n'.format(num_validation_examples))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Classes: 5\n",
            "Total Number of Training Images: 2569\n",
            "Total Number of Validation Images: 1101 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG_aMDclYAPl",
        "colab_type": "text"
      },
      "source": [
        "The images in the Flowers dataset are not all the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKrps7QSYBP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c0eb07f3-cc3a-4978-eb73-417957975abe"
      },
      "source": [
        "for i, example in enumerate(training_set.take(5)):\n",
        "  print('Image {} shape: {} label: {}'.format(i+1, example[0].shape, example[1]) )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image 1 shape: (333, 500, 3) label: 2\n",
            "Image 2 shape: (212, 320, 3) label: 3\n",
            "Image 3 shape: (240, 320, 3) label: 3\n",
            "Image 4 shape: (240, 320, 3) label: 4\n",
            "Image 5 shape: (317, 500, 3) label: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2vre4OEZ7o9",
        "colab_type": "text"
      },
      "source": [
        "# Reformat Images and Create Batches\n",
        "In the cell below create a function that reformats all images to the resolution expected by MobileNet v2 (224, 224) and normalizes them. The function should take in an image and a label as arguments and should return the new image and corresponding label. Then create training and validation batches of size 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_7b_smBZ8W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_RES = 224\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255\n",
        "  return image, label\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ks5-5Dtv7-M",
        "colab_type": "text"
      },
      "source": [
        "# Do Simple Transfer Learning with TensorFlow Hub\n",
        "Let's now use TensorFlow Hub to do Transfer Learning. Remember, in transfer learning we reuse parts of an already trained model and change the final layer, or several layers, of the model, and then retrain those layers on our own dataset.\n",
        "\n",
        "# Create a Feature Extractor\n",
        "In the cell below create a feature_extractor using MobileNet v2. Remember that the partial model from TensorFlow Hub (without the final classification layer) is called a feature vector. Go to the TensorFlow Hub documentation to see a list of available feature vectors. Click on the tf2-preview/mobilenet_v2/feature_vector. Read the documentation and get the corresponding URL to get the MobileNet v2 feature vector. Finally, create a feature_extractor by using hub.KerasLayer with the correct input_shape parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gzm-SCRwuBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES,3))"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}